%%%present some benchmark results

To check the overall performance of the \cpp{mdarray} template provided by the
library benchmark programs have been written whose results will be presented in
this chapter.  
Three particular aspects are investigated by the benchmarks 
\begin{itemize}
\item linear data access via iterators
\item data access via multidimensional indexes 
\item performance of the arithmetic operators
\end{itemize}
To keep the number of benchmark results within reasonable bounds all benchmarks
have been performend with the three predefined specializations of the
\cpp{mdarray} template: \cpp{dynamic\_array}, \cpp{fixed\_dim\_array}, and 
\cpp{static\_array}. In addition to the plain array templates also their view
types have been taken into account. The view types are interesting as they add
some additional code which may cause some overhead. 

Its (presumed) outstanding performance is the reason why so much scientific
software is written in C. In order to show that the code provided by
\libpnicore\ can be used in high performance applications all benchmarks are
normalized to the runtime of equivalient C code. In most situations this means
that data access is done via simple pointers.

%%%===========================================================================
\section{Iterator benchmarks}

%%%---------------------------------------------------------------------------
\begin{table}[tb]
\centering
\begin{minipage}{0.65\linewidth}
\begin{tabular}{l||c|c}
array type & iterator (r/w) & view iterator (r/w)  \\
\hline\hline
\cpp{dynamic\_array} & $1.02$/$1.04$ & $2.50$/$2.96$ \\
\hline
\cpp{fixed\_dim\_array} & $0.99$/$1.00$ & $2.52$/$2.89$ \\
\hline
\cpp{static\_array} & $1.00$/$1.00$ & $2.07$/$2.40$ \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.34\linewidth}
\caption{
\label{tab:benchmarks:iter}
Results for the iterator benchmark. \emph{r} and \emph{w} denote reading and
writing results respectively.}
\end{minipage}
\end{table}

%%%---------------------------------------------------------------------------
\begin{listing}[tb]
\centering
\begin{minipage}[b]{0.4\linewidth}
\begin{minted}[label=iteartor writing]{cpp}
for(auto &x: data) 
    x = buffer;
\end{minted} 
\end{minipage}
\hspace{0.1\linewidth}
\begin{minipage}[b]{0.4\linewidth}
\begin{minted}{cpp}
T *data = new T[N];

for(size_t i=0;i<N;++i) 
    data[i] = buffer;
\end{minted}
\end{minipage}
\caption{\label{lst:benchmarks:iterator_write}
The left snippet shows the core of the iterator writing benchmark and the right
one the equivalent code using plain pointers.
}
\end{listing}

%%%---------------------------------------------------------------------------
\begin{listing}[tb]
\centering
\begin{minipage}{0.4\linewidth}
\begin{minted}{cpp}
for(auto x: data)
    buffer = x;
\end{minted}
\end{minipage}
\hspace{0.1\linewidth}
\begin{minipage}{0.4\linewidth}
\begin{minted}{cpp}
T *data = new T[N];

for(size_t i=0;i<N;++i)
    buffer = data[i];
\end{minted}
\end{minipage}
\caption{\label{lst:benchmarks:iterator_read}
The left snippet shows the core of the iterator reading benchmark and the right
one the equivalent code using plain pointers.
}
\end{listing}

The essential loops whose runtime is measured for this benchmark is shown in
Listings~\ref{lst:benchmarks:iterator_write} and
\ref{lst:benchmarks:iterator_read}. It should be mentioned that for the pointer
code only the loop is measured without the time required for allocating memory.

The benchmark results are summarized in Tab.~\ref{tab:benchmarks:iter}. All
numbers in this table are normalized to the raw pointer performance and thus
reflect directly any performance penalty or advantage over direct pointer
access. Table~\ref{tab:benchmarks:iter} shows a small performance penalty
of $2$ to $4$ \% for  the \cpp{dynamic\_array}. For \cpp{fixed\_dim\_array} 
and \cpp{static\_array} iterator access is as fast as accessing the data 
via a pointer. 
In all cases iterating over a view shows significant performance penalties. 
Using iterators on views is about $2$ up to $3$ times slower than accessing 
the data via a pointer. This is simply due to additional overhead the 
view template introduces. 


%%%===========================================================================
\section{Multidimensional index access}

%%%---------------------------------------------------------------------------
\begin{table}[tb]
\centering
\begin{tabular}{l||c|c|c}
array type & variadic (r/w) & vector (r/w) & array (r/w) \\
\hline\hline
\cpp{dynamic\_array}      & $1.03$/$1.02$ & $3.82$/$4.63$ & $3.33$/$3.76$ \\
\cpp{dynamci\_array}-view & $3.39$/$6.31$ & $6.29$/$6.49$ & $4.23$/$5.41$ \\
\hline
\cpp{fixed\_dim\_array}      & $0.94$/$0.97$ & $3.27$/$3.79$ & $3.29$/$3.53$ \\
\cpp{fixed\_dim\_array}-view & $3.27$/$6.04$ & $5.02$/$6.26$ & $4.03$/$5.15$ \\
\hline
\cpp{static\_array}      & $0.97$/$0.97$ & $3.08$/$3.75$ & $3.25$/$3.67$ \\
\cpp{static\_array}-view & $2.78$/$3.58$ & $4.66$/$5.92$ & $4.83$/$5.33$ \\
\hline
\end{tabular}
\caption{
\label{tab:benchmarks:multidim}
Results for the muldimensional index access benchmarks. For array views a 
significant overhead is added. This makes views at the current state of
development rather useless for high performance applications.
}
\end{table}

%%%---------------------------------------------------------------------------
\begin{listing}[tb]
\centering
\begin{tabular}{p{0.3\linewidth}p{0.05\linewidth}p{0.55\linewidth}}
\begin{minted}{cpp}
for(size_t i=0;i<nx;++i)
    for(size_t j=0;j<ny;++j)
        data(i,j) = buffer;
\end{minted} 
& & 
\begin{minted}{cpp}
for(index[0]=0;index[0]<nx;++index[0])
    for(index[1]=0;index[1]<ny;++index[1])
        data(index) = buffer;
\end{minted}
\\
\multicolumn{1}{c}{\textbf{variadic index}} & & 
\multicolumn{1}{c}{\textbf{vector/array index}} \\
\begin{minted}{cpp}
for(size_t i=0;i<nx;++i)
    for(size_t j=0;j<ny;++j)
        data[i*ny+j] = buffer;
\end{minted} 
& & \\
\multicolumn{1}{c}{\textbf{pointer access}} & & \\
\end{tabular}
\caption{\label{lst:benchmarks:mindex_write}
Basic loop constructions measured for the multiindex write benchmarks. The code
for reading is basically the same - just flip the RHS and LHS of the assignment
operator.}
\end{listing}

One of the major goals for \libpnicore\ was to provide an array type which is as
easy and intuitive to use as the multidimensional array types provided by
Fortran or the numpy Python package. This includes easy access to array elements
using a multidimensional index which can be passed either as a variadic list of 
integers or as a container of an integer type. 
This immediately raises the question how fast data access via multidimensional 
indices is  in comparison with simple pointer access where the linear offset is
computed from the multidimensional index and the number of elements along each
dimension of the array. 

The results for the benchmark are shown in Tab.~\ref{tab:benchmarks:multidim}.
It follows immediately from this table that passing the multidimensional index
as a variadic argument list is the fastest way of how to access the data. 
The performance is virtually equal to those of using direct pointer access. 
Using the container types \cpp{std::vector} or \cpp{std::array} to pass the
index will cause in a performance penalty of $200$ to $300$ \% for virtually all
array types. 
As with linear access via iterators there is a significant performance penalty
when accessing data via a view. One surprising aspect of the results shown in 
Tab.~\ref{tab:benchmarks:multidim} is the fact that at least for 
\cpp{fixed\_dim\_array} and \cpp{static\_array} variadic access outperforms even 
pointer access.

The reason for the huge performance penalties is yet unclear. However, we hope
that they can be reduced in further releases. 

Finally Listing~\ref{lst:benchmarks:mindex_write} shows the basic code that has
been measured for this benchmark (in this particular case for writing data). The
code used for reading data is virtually the same just flip the RHS and the LHS
arguments of the assignment operator.

%%%===========================================================================
\section{Arithmetics}

Last but not least a feasible  array type has to provide arithmetic operators 
of reasonable performance. This last section compares the unary and binary
arithmetic operators for the \cpp{mdarray} specializations. 
Unlike for the other benchmarks the arithmetic benchmarks cover only the 
\cpp{dynamic\_array} and \cpp{fixed\_dim\_array} specializations of 
\cpp{mdarray}.

\subsection{Unary arithmetics}
\begin{table}
\centering
\begin{minipage}{0.6\linewidth}
\begin{tabular}{l||c|c}
operation & \cpp{dynamic\_array} & \cpp{fixed\_dim\_array} \\ 
\hline\hline
$a*=b$ & $1.00$ & $1.00$ \\
\hline
$a*=s$ & $0.77$ & $0.77$ \\
\hline
$a/=b$ & $1.00$ & $1.00$ \\
\hline
$a/=s$ & $1.00$ & $1.00$ \\
\hline
$a+=b$ & $1.00$ & $1.00$ \\
\hline
$a+=s$ & $0.77$ & $0.77$ \\
\hline
$a-=b$ & $1.00$ & $1.00$ \\
\hline
$a-=s$ & $0.77$ & $0.77$ \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.39\linewidth}
\caption{\label{tab:benchmarks:unary} 
Results for the unary arithmetic benchmarks. Both benchmarked types show rather 
similar performance. It is interesting, however, that in some cases the array
types seem to outperform the pointer implementation.
}
\end{minipage}
\end{table}
\libpnicore s \cpp{mdarray} template provides the following unary arithmetic
operators
\begin{itemize}
    \item \cpp{+=} unary addition
    \item \cpp{-=} unary subtraction
    \item \cpp{*=} unary multiplication
    \item \cpp{/=} unary division
\end{itemize}
where the operations are applied element-wise on the LHS of the operator.
All operators accept either an array type or a scalar type as their RHS. 
The results for the benchmark are shown in Tab.~\ref{tab:benchmarks:unary}. 
As can be obtained from Tab.~\ref{tab:benchmarks:unary}
the unary arithmetic operations are as fast as their equivalent implementations
using simple pointer access. Indeed in some cases the operators are faster than
the pointer approach. The $s$ and $b$ on the RHS of the operator in
Tab.~\ref{tab:benchmarks:unary} denote scalar and array arguments on the RHS of
the operator respectively.

\subsection{Binary arithmetics}

\begin{table}
\centering
\begin{tabular}{l||c|c|c}
operation & \cpp{dynamic\_array} & \cpp{fixed\_dim\_array} & Fortran \\
\hline\hline
$a+b$ & $1.04$ & $1.00$ & $2.18$ \\
\hline
$a-b$ & $1.02$ & $1.00$ & $2.18$ \\
\hline
$a\times b$ & $1.05$ & $1.00$ & $2.24$ \\
\hline
$a/b$ & $1.02$ & $1.00$ & $1.46$ \\
\hline
$a\times b + \frac{d-e}{f}$ & $1.04$ & $1.00$ & $1.49$ \\
\hline
\end{tabular}
\caption{\label{tab:benchmarks:binary}
Results for the binary arithmetic benchmarks normalized to the raw pointer
implementation of the operations.
}
\end{table}
As already mentioned binary arithmetic operations are implemented with
expression templates. Though the reference for the binary benchmarks are still
their equivalent C expressions Fortran has also been included in the benchmark. 
This is in so far of importance as Fortran is, until today, considered the
ultimate language for numerics. 
The results for the binary arithmetic benchmarks are shown in
Tab.~\ref{tab:benchmarks:binary}. The first conclusion which can be drawn from
this table is the fact that \cpp{dynamic\_array} shows an up to $5$ \% 
performance penalty over C code while \cpp{fixed\_dim\_array} is virtually as
fast as the C implementation of the tested operations. 
The most astonishing result is, however, the rather low performance of Fortran
not only in comparison with the C++ types but also with respect to the C
implementation of the operations (as can be seen from the last column of 
Tab.~\ref{tab:benchmarks:binary}). 

The reason for the bad performance is not yet clear. It might be due to the poor
quality of the compiler (we only tested with \cpp{gfortran} from the GNU
compiler collection). Thus the tests should be repeated using for instance
Intel's compiler suite. On the other handside: the GNU compiler collection is
the most important for our uses which makes the results for this set of
compilers the most relevant. Another reason might be that the benchmark code is
written in C++ and the Fortran functions are linked into the C++ code
statically. It may be possible that this has some negative effect on the
performance of the Fortran code. Whatever might be the reason far the bad
Fortran results, a single conclusion can be drawn from this benchmark: 
Expression templates are a very sensible way to implement operators in C++ and
may can help to push C++ in the field of scientific computing.
