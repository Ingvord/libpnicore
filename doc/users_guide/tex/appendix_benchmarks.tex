%%%present some benchmark results

To check the overall performance of the \cpp{mdarray} template provided by the
library benchmark programs have been written whose results will be presented in
this chapter.  
Three particular aspects are investigated by the benchmarks 
\begin{itemize}
\item linear data access via iterators
\item data access via multidimensional indexes 
\item performance of the arithmetic operators
\end{itemize}
To keep the number of benchmark results within reasonable bounds all benchmarks
have been performend with the three predefined specializations of the
\cpp{mdarray} template: \cpp{dynamic\_array}, \cpp{fixed\_dim\_array}, and 
\cpp{static\_array}. In addition to the plain array templates also their view
types have been taken into account. The view types are interesting as they add
some additional code which may cause some overhead. 

Its (presumed) outstanding performance is the reason why so much scientific
software is written in C. In order to show that the code provided by
\libpnicore\ can be used in high performance applications all benchmarks are
normalized to the runtime of equivalient C code. In most situations this means
that data access is done via simple pointers.

%%%===========================================================================
\section{Iterator benchmarks}

%%%---------------------------------------------------------------------------
\begin{table}[tb]
\centering
\begin{minipage}{0.65\linewidth}
\begin{tabular}{l||c|c}
array type & iterator (r/w) & view iterator (r/w)  \\
\hline\hline
\cpp{dynamic\_array} & $1.02$/$1.04$ & $2.50$/$2.96$ \\
\hline
\cpp{fixed\_dim\_array} & $0.99$/$1.00$ & $2.52$/$2.89$ \\
\hline
\cpp{static\_array} & $1.00$/$1.00$ & $2.07$/$2.40$ \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.34\linewidth}
\caption{
\label{tab:benchmarks:iter}
Results for the iterator benchmark. \emph{r} and \emph{w} denote reading and
writing results respectively.}
\end{minipage}
\end{table}

%%%---------------------------------------------------------------------------
\begin{listing}[tb]
\centering
\begin{minipage}[b]{0.4\linewidth}
\begin{minted}[label=iteartor writing]{cpp}
for(auto &x: data) 
    x = buffer;
\end{minted} 
\end{minipage}
\hspace{0.1\linewidth}
\begin{minipage}[b]{0.4\linewidth}
\begin{minted}{cpp}
T *data = new T[N];

for(size_t i=0;i<N;++i) 
    data[i] = buffer;
\end{minted}
\end{minipage}
\caption{\label{lst:benchmarks:iterator_write}
The left snippet shows the core of the iterator writing benchmark and the right
one the equivalent code using plain pointers.
}
\end{listing}

%%%---------------------------------------------------------------------------
\begin{listing}[tb]
\centering
\begin{minipage}{0.4\linewidth}
\begin{minted}{cpp}
for(auto x: data)
    buffer = x;
\end{minted}
\end{minipage}
\hspace{0.1\linewidth}
\begin{minipage}{0.4\linewidth}
\begin{minted}{cpp}
T *data = new T[N];

for(size_t i=0;i<N;++i)
    buffer = data[i];
\end{minted}
\end{minipage}
\caption{\label{lst:benchmarks:iterator_read}
The left snippet shows the core of the iterator reading benchmark and the right
one the equivalent code using plain pointers.
}
\end{listing}

The essential loops whose runtime is measured for this benchmark is shown in
Listings~\ref{lst:benchmarks:iterator_write} and
\ref{lst:benchmarks:iterator_read}. It should be mentioned that for the pointer
code only the loop is measured without the time required for allocating memory.

The benchmark results are summarized in Tab.~\ref{tab:benchmarks:iter}. All
numbers in this table are normalized to the raw pointer performance and thus
reflect directly any performance penalty or advantage over direct pointer
access. Table~\ref{tab:benchmarks:iter} shows a small performance penalty
of $2$ to $4$ \% for  the \cpp{dynamic\_array}. For \cpp{fixed\_dim\_array} 
and \cpp{static\_array} iterator access is as fast as accessing the data 
via a pointer. 
In all cases iterating over a view shows significant performance penalties. 
Using iterators on views is about $2$ up to $3$ times slower than accessing 
the data via a pointer. This is simply due to additional overhead the 
view template introduces. 


%%%===========================================================================
\section{Multidimensional index access}

%%%---------------------------------------------------------------------------
\begin{table}[tb]
\centering
\begin{tabular}{l||c|c|c}
array type & variadic (r/w) & vector (r/w) & array (r/w) \\
\hline\hline
\cpp{dynamic\_array}      & $1.03$/$1.02$ & $3.82$/$4.63$ & $3.33$/$3.76$ \\
\cpp{dynamci\_array}-view & $3.39$/$6.31$ & $6.29$/$6.49$ & $4.23$/$5.41$ \\
\hline
\cpp{fixed\_dim\_array}      & $0.94$/$0.97$ & $3.27$/$3.79$ & $3.29$/$3.53$ \\
\cpp{fixed\_dim\_array}-view & $3.27$/$6.04$ & $5.02$/$6.26$ & $4.03$/$5.15$ \\
\hline
\cpp{static\_array}      & $0.97$/$0.97$ & $3.08$/$3.75$ & $3.25$/$3.67$ \\
\cpp{static\_array}-view & $2.78$/$3.58$ & $4.66$/$5.92$ & $4.83$/$5.33$ \\
\hline
\end{tabular}
\caption{
\label{tab:benchmarks:multidim}
Results for the muldimensional index access benchmarks. For array views a 
significant overhead is added. This makes views at the current state of
development rather useless for high performance applications.
}
\end{table}

%%%---------------------------------------------------------------------------
\begin{listing}[tb]
\centering
\begin{tabular}{p{0.3\linewidth}p{0.05\linewidth}p{0.55\linewidth}}
\begin{minted}{cpp}
for(size_t i=0;i<nx;++i)
    for(size_t j=0;j<ny;++j)
        data(i,j) = buffer;
\end{minted} 
& & 
\begin{minted}{cpp}
for(index[0]=0;index[0]<nx;++index[0])
    for(index[1]=0;index[1]<ny;++index[1])
        data(index) = buffer;
\end{minted}
\\
\multicolumn{1}{c}{\bf{variadic index}} & & 
\multicolumn{1}{c}{\bf{vector/array index}} \\
\begin{minted}{cpp}
for(size_t i=0;i<nx;++i)
    for(size_t j=0;j<ny;++j)
        data[i*ny+j] = buffer;
\end{minted} 
& & \\
\multicolumn{1}{c}{\bf{pointer access}} & & \\
\end{tabular}
\caption{\label{lst:benchmarks:mindex_write}
Basic loop constructions measured for the multiindex write benchmarks. The code
for reading is basically the same - just flip the RHS and LHS of the assignment
operator.}
\end{listing}

One of the major goals for \libpnicore\ was to provide an array type which is as
easy and intuitive to use as the multidimensional array types provided by
Fortran or the numpy Python package. This includes easy access to array elements
using a multidimensional index which can be passed either as a variadic list of 
integers or as a container of an integer type. 
This immediately raises the question how fast data access via multidimensional 
indices is  in comparison with simple pointer access where the linear offset is
computed from the multidimensional index and the number of elements along each
dimension of the array. 

The results for the benchmark are shown in Tab.~\ref{tab:benchmarks:multidim}.
It follows immediately from this table that passing the multidimensional index
as a variadic argument list is the fastest way of how to access the data. 
The performance is virtually equal to those of using direct pointer access. 
Using the container types \cpp{std::vector} or \cpp{std::array} to pass the
index will cause in a performance penalty of $200$ to $300$ \% for virtually all
array types. 
As with linear access via iterators there is a significant performance penalty
when accessing data via a view. One surprising aspect of the results shown in 
Tab.~\ref{tab:benchmarks:multidim} is the fact that at least for 
\cpp{fixed\_dim\_array} and \cpp{static\_array} variadic access outperforms even 
pointer access.

The reason for the huge performance penalties is yet unclear. However, we hope
that they can be reduced in further releases. 

Finally Listing~\ref{lst:benchmarks:mindex_write} shows the basic code that has
been measured for this benchmark (in this particular case for writing data). The
code used for reading data is virtually the same just flip the RHS and the LHS
arguments of the assignment operator.

%%%===========================================================================
\section{Arithmetics}

\subsection{Unary arithmetics}
\begin{table}
\centering
\begin{minipage}{0.6\linewidth}
\begin{tabular}{l||c|c}
operation & \cpp{dynamic\_array} & \cpp{fixed\_dim\_array} \\ 
\hline\hline
$a*=b$ & $1.00$ & $1.00$ \\
\hline
$a*=s$ & $0.77$ & $0.77$ \\
\hline
$a/=b$ & $1.00$ & $1.00$ \\
\hline
$a/=s$ & $1.00$ & $1.00$ \\
\hline
$a+=b$ & $1.00$ & $1.00$ \\
\hline
$a+=s$ & $0.77$ & $0.77$ \\
\hline
$a-=b$ & $1.00$ & $1.00$ \\
\hline
$a-=s$ & $0.77$ & $0.77$ \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.39\linewidth}
\caption{\label{tab:benchmarks:unary} 
Results for the unary arithmetic benchmarks. Both benchmarked types show rather 
similar performance. It is interesting, however, that in some cases the array
types seem to outperform the pointer implementation.
}
\end{minipage}
\end{table}

\subsection{Binary arithmetics}

\begin{table}
\centering
\begin{tabular}{l||c|c|c}
operation & \cpp{dynamic\_array} & \cpp{fixed\_dim\_array} & Fortran \\
\hline\hline
$a+b$ & $1.04$ & $1.00$ & $2.18$ \\
\hline
$a-b$ & $1.02$ & $1.00$ & $2.18$ \\
\hline
$a\times b$ & $1.05$ & $1.00$ & $2.24$ \\
\hline
$a/b$ & $1.02$ & $1.00$ & $1.46$ \\
\hline
$a\times b + \frac{d-e}{f}$ & $1.04$ & $1.00$ & $1.49$ \\
\hline
\end{tabular}
\caption{\label{tab:benchmarks:binary}
Results for the binary arithmetic benchmarks normalized to the raw pointer
implementation of the operations.
}
\end{table}
